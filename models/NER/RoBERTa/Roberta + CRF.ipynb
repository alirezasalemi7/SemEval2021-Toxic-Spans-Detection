{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Roberta + CRF.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9441d6b4425343fa835047b25e2f6d93":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cf432f2397eb468b990c7bdf23506f24","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f3dbb486c88f40ba8486b6d12ed5f55f","IPY_MODEL_58df53fe8a224e5b96d23876d22d9ca1"]}},"cf432f2397eb468b990c7bdf23506f24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f3dbb486c88f40ba8486b6d12ed5f55f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_269f9dce06f14c34a491e35b95a72248","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":481,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":481,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_544ad5a619fc46feb1f0f5557329e0a5"}},"58df53fe8a224e5b96d23876d22d9ca1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_78172c8fcc9142b4bc442af68f33e196","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 481/481 [00:24&lt;00:00, 19.5B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1018b934d96c429487e1ed60228bac70"}},"269f9dce06f14c34a491e35b95a72248":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"544ad5a619fc46feb1f0f5557329e0a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78172c8fcc9142b4bc442af68f33e196":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1018b934d96c429487e1ed60228bac70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2962b265d8b24fc7ad106163833a58c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f475adb86ff54646ae4aa7729e0aefc4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cf0b2490176a4c60bb66fbb4c0d32e26","IPY_MODEL_07e9040425834cce9420f00035b09b29"]}},"f475adb86ff54646ae4aa7729e0aefc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cf0b2490176a4c60bb66fbb4c0d32e26":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0d07a380c35c47dc9fa99eafca7ad606","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":657434796,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":657434796,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5e09ce6254914c56a40db89feb6cd81a"}},"07e9040425834cce9420f00035b09b29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bd6458143a374d60981bba258c3f7b3c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 657M/657M [00:24&lt;00:00, 26.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f8a0af4fd23546168fbc92771ec10c2d"}},"0d07a380c35c47dc9fa99eafca7ad606":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5e09ce6254914c56a40db89feb6cd81a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bd6458143a374d60981bba258c3f7b3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f8a0af4fd23546168fbc92771ec10c2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d617qgDGLsCm","executionInfo":{"status":"ok","timestamp":1611439679694,"user_tz":-210,"elapsed":711,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}},"outputId":"be2c4526-c507-4d05-b672-de3c0af4256b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QkY6Pa14-uSW","executionInfo":{"status":"ok","timestamp":1611427827473,"user_tz":-210,"elapsed":4523,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}}},"source":["!cp \"/content/drive/My Drive/toxic span/toxic_span_practice.csv\" \"./toxic_span_practice.csv\"\n","!cp \"/content/drive/My Drive/toxic span/toxic_span_train.csv\" \"./toxic_span_train.csv\""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GK9vjlbznhTZ","executionInfo":{"status":"ok","timestamp":1611427835843,"user_tz":-210,"elapsed":11510,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}},"outputId":"e60f26cb-1cc1-4d5e-b8d3-7ba12e3e24a8"},"source":["!pip install stanza\n","!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting stanza\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/8b/3a9e7a8d8cb14ad6afffc3983b7a7322a3a24d94ebc978a70746fcffc085/stanza-1.1.1-py3-none-any.whl (227kB)\n","\r\u001b[K     |█▍                              | 10kB 26.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20kB 32.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 30kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 40kB 26.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 51kB 24.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 61kB 27.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 71kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 81kB 19.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 92kB 18.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 102kB 18.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 112kB 18.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 122kB 18.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 133kB 18.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 143kB 18.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 153kB 18.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 163kB 18.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 174kB 18.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 184kB 18.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 194kB 18.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 204kB 18.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 215kB 18.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 225kB 18.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235kB 18.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanza) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanza) (4.41.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanza) (3.12.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanza) (2.23.0)\n","Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from stanza) (1.7.0+cu101)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (51.3.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2.10)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.16.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.8)\n","Installing collected packages: stanza\n","Successfully installed stanza-1.1.1\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 16.5MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 31.8MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 55.9MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=49ec3b48f8138d810b1cd1ea7e96c3642cc9c48cbf00ac4ce50b0b1a9d0cecb8\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uZcqPZAZbhEB","executionInfo":{"status":"ok","timestamp":1611441119691,"user_tz":-210,"elapsed":4974,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}}},"source":["import pandas as pd\n","import numpy as np\n","import gc\n","import json\n","import stanza\n","from tensorflow.keras import *\n","import tensorflow as tf\n","from tensorflow.keras import *\n","import tensorflow.keras.backend as K\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import classification_report\n","from transformers import TFRobertaModel,RobertaTokenizer"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"opPxhbPHPQoZ","executionInfo":{"status":"ok","timestamp":1611441119692,"user_tz":-210,"elapsed":3659,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}}},"source":["test_set = pd.read_csv(\"toxic_span_practice.csv\")\n","test_set['spans'] = test_set['spans'].apply(lambda x : json.loads(x))\n","train_set = pd.read_csv(\"toxic_span_train.csv\")\n","train_set['spans'] = train_set['spans'].apply(lambda x : json.loads(x))\n","toxic_span_dataset = test_set.append(train_set,ignore_index=True)\n","toxic_span_dataset['text'] = toxic_span_dataset['text'].apply(lambda x : x.lower())"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"I07cu0iEor7X","executionInfo":{"status":"ok","timestamp":1611441119693,"user_tz":-210,"elapsed":2216,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}}},"source":["def createNEROutputs(texts,spans,max_length,tokenizer):\n","    outputs = []\n","    for text,span in zip(texts,spans):\n","        output = np.zeros(max_length*3,dtype=np.float).reshape((max_length,3))\n","        tokens = tokenizer.tokenize(text)[:max_length]\n","        length = 0\n","        start = True\n","        for i in range(len(tokens),max_length):\n","            output[i,0] = 1.0\n","        for index,token in enumerate(tokens):\n","            sub = True\n","            if \"Ġ\" in token:\n","                sub = False\n","                token = token[1:]\n","            if not start:\n","                next_index = text[length:].find(token)\n","                if next_index == 0:\n","                    sub = True\n","                length += next_index\n","            # if length in span and not sub:\n","            #     output[index,2] = 1.0\n","            #     output[index,0] = 0.0\n","            if length in span:\n","                output[index,2] = 1.0\n","                output[index,0] = 0.0\n","            else:\n","                output[index,1] = 1.0\n","                output[index,0] = 0.0\n","            length += len(token)\n","            start = False\n","        outputs.append(output)\n","    return np.array(outputs)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"GbejXea8fbTo","executionInfo":{"status":"ok","timestamp":1611441120035,"user_tz":-210,"elapsed":538,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}}},"source":["def NERGetIndicesSingleText(outputs,text,tokenizer):\n","    outputs = tf.argmax(outputs,axis=-1)\n","    tokens = tokenizer.tokenize(text)\n","    index = 0\n","    indexes = []\n","    sub = False\n","    prev = False\n","    for token,output in zip(tokens,outputs):\n","        if token[0] == \"Ġ\":\n","            token = token[1:]\n","            sub = False\n","        elif token.isalpha():\n","            sub = True\n","        else:\n","            sub = False\n","        temp_index = text[index:].find(token)\n","        temp_start = index+temp_index\n","        if output == 2 or (sub and prev and output != 0):\n","            prev = True\n","            indexes = indexes + list(range(temp_start,temp_start+len(token)))\n","        else:\n","            prev = False\n","        index = temp_start+len(token)\n","    return np.array(indexes)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"REsioW8lqyhT","executionInfo":{"status":"ok","timestamp":1611441122083,"user_tz":-210,"elapsed":707,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}}},"source":["def createIndicesForNERModel(predicts,texts,tokenizer):\n","    outputs = []\n","    for text,pred in zip(texts,predicts):\n","         indices = NERGetIndicesSingleText(pred,text,tokenizer)\n","         outputs.append(indices)\n","    return outputs"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"OjTYF4wQ_-Rg","executionInfo":{"status":"ok","timestamp":1611441122998,"user_tz":-210,"elapsed":465,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}}},"source":["def f1(preds,trues):\n","    if len(trues) == 0:\n","        return 1. if len(preds) == 0 else 0.\n","    if len(preds) == 0:\n","        return 0.\n","    predictions_set = set(preds)\n","    gold_set = set(trues)\n","    nom = 2 * len(predictions_set.intersection(gold_set))\n","    denom = len(predictions_set) + len(gold_set)\n","    return float(nom)/float(denom)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZlzBi7ZyAMsP","executionInfo":{"status":"ok","timestamp":1611441124955,"user_tz":-210,"elapsed":774,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}}},"source":["def avg_f1(preds,trues):\n","    avg_f1_total = 0.0\n","    for pred,true in zip(preds,trues):\n","        avg_f1_total += f1(pred,true)\n","    return avg_f1_total/len(preds)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y5bPVXNfC_gA","executionInfo":{"status":"ok","timestamp":1611441126915,"user_tz":-210,"elapsed":815,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}}},"source":["class F1Metric(callbacks.Callback):\n","    def __init__(self,inputs,labels,spans,texts,test=True):\n","        self.inputs = inputs\n","        self.spans = spans\n","        self.tokenizer = tokenizer\n","        self.texts = texts\n","        self.test = test\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        preds = self.model.predict(self.inputs,verbose=0)\n","        indices = createIndicesForNERModel(preds,texts,tokenizer)\n","        f1 = avg_f1(indices,self.spans)\n","        if self.test:\n","            print()\n","            print(\"test f1 = \"+str(f1))\n","        else:\n","            print()\n","            print(\"train f1 = \"+str(f1))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"uWH-LpFvhys1","executionInfo":{"status":"ok","timestamp":1611441128591,"user_tz":-210,"elapsed":701,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}}},"source":["def createInputForNER(texts,max_length,tokenizer):\n","    input_length = []\n","    for text in texts:\n","        input_length.append(min(max_length,len(tokenizer.tokenize(text))))\n","    tokens = tokenizer(texts,padding=\"max_length\",max_length=max_length,return_tensors=\"tf\",truncation=True)\n","    data = [np.array(tokens['input_ids']),np.array(tokens['attention_mask']),np.array(input_length)]\n","    return data"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2sd7ByGjPhP7"},"source":["# CRF Layer"]},{"cell_type":"code","metadata":{"id":"fhuwwqF2ABZP","executionInfo":{"status":"ok","timestamp":1611441130902,"user_tz":-210,"elapsed":798,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}}},"source":["#https://github.com/Hironsan/keras-crf-layer/blob/master/crf.py\n","import tensorflow as tf\n","from keras import backend as K\n","from keras.engine import Layer, InputSpec\n","import tensorflow_addons as tfa\n","\n","try:\n","    from tensorflow.contrib.crf import crf_decode\n","except ImportError:\n","    from tensorflow.python.framework import dtypes\n","    from tensorflow.python.ops import array_ops, gen_array_ops, math_ops, rnn, rnn_cell\n","\n","\n","    class CrfDecodeForwardRnnCell(rnn_cell.RNNCell):\n","        def __init__(self, transition_params):\n","            self._transition_params = array_ops.expand_dims(transition_params, 0)\n","            self._num_tags = transition_params.get_shape()[0]\n","\n","        @property\n","        def state_size(self):\n","            return self._num_tags\n","\n","        @property\n","        def output_size(self):\n","            return self._num_tags\n","\n","        def __call__(self, inputs, state, scope=None):\n","            state = array_ops.expand_dims(state, 2)  # [B, O, 1]\n","            transition_scores = state + self._transition_params  # [B, O, O]\n","            new_state = inputs + math_ops.reduce_max(transition_scores, [1])  # [B, O]\n","            backpointers = math_ops.argmax(transition_scores, 1)\n","            backpointers = math_ops.cast(backpointers, dtype=dtypes.int32)  # [B, O]\n","            return backpointers, new_state\n","\n","\n","    class CrfDecodeBackwardRnnCell(rnn_cell.RNNCell):\n","        def __init__(self, num_tags):\n","            self._num_tags = num_tags\n","\n","        @property\n","        def state_size(self):\n","            return 1\n","\n","        @property\n","        def output_size(self):\n","            return 1\n","\n","        def __call__(self, inputs, state, scope=None):\n","            state = array_ops.squeeze(state, axis=[1])  # [B]\n","            batch_size = array_ops.shape(inputs)[0]\n","            b_indices = math_ops.range(batch_size)  # [B]\n","            indices = array_ops.stack([b_indices, state], axis=1)  # [B, 2]\n","            new_tags = array_ops.expand_dims(\n","                gen_array_ops.gather_nd(inputs, indices),  # [B]\n","                axis=-1)  # [B, 1]\n","\n","            return new_tags, new_tags\n","\n","\n","    def crf_decode(potentials, transition_params, sequence_length):\n","        num_tags = potentials.get_shape()[2]\n","\n","        # Computes forward decoding. Get last score and backpointers.\n","        crf_fwd_cell = CrfDecodeForwardRnnCell(transition_params)\n","        initial_state = array_ops.slice(potentials, [0, 0, 0], [-1, 1, -1])\n","        initial_state = array_ops.squeeze(initial_state, axis=[1])  # [B, O]\n","        inputs = array_ops.slice(potentials, [0, 1, 0], [-1, -1, -1])  # [B, T-1, O]\n","        backpointers, last_score = rnn.dynamic_rnn(\n","            crf_fwd_cell,\n","            inputs=inputs,\n","            sequence_length=sequence_length - 1,\n","            initial_state=initial_state,\n","            time_major=False,\n","            dtype=dtypes.int32)  # [B, T - 1, O], [B, O]\n","        backpointers = gen_array_ops.reverse_sequence(backpointers, sequence_length - 1, seq_dim=1)  # [B, T-1, O]\n","\n","        # Computes backward decoding. Extract tag indices from backpointers.\n","        crf_bwd_cell = CrfDecodeBackwardRnnCell(num_tags)\n","        initial_state = math_ops.cast(math_ops.argmax(last_score, axis=1), dtype=dtypes.int32)  # [B]\n","        initial_state = array_ops.expand_dims(initial_state, axis=-1)  # [B, 1]\n","        decode_tags, _ = rnn.dynamic_rnn(\n","            crf_bwd_cell,\n","            inputs=backpointers,\n","            sequence_length=sequence_length - 1,\n","            initial_state=initial_state,\n","            time_major=False,\n","            dtype=dtypes.int32)  # [B, T - 1, 1]\n","        decode_tags = array_ops.squeeze(decode_tags, axis=[2])  # [B, T - 1]\n","        decode_tags = array_ops.concat([initial_state, decode_tags], axis=1)  # [B, T]\n","        decode_tags = gen_array_ops.reverse_sequence(decode_tags, sequence_length, seq_dim=1)  # [B, T]\n","\n","        best_score = math_ops.reduce_max(last_score, axis=1)  # [B]\n","        return decode_tags, best_score\n","\n","\n","class CRFLayer(Layer):\n","\n","    def __init__(self, transition_params=None, **kwargs):\n","        super(CRFLayer, self).__init__(**kwargs)\n","        self.transition_params = transition_params\n","        self.input_spec = [InputSpec(ndim=3), InputSpec(ndim=2)]\n","        self.supports_masking = True\n","\n","    def compute_output_shape(self, input_shape):\n","        assert input_shape and len(input_shape[0]) == 3\n","\n","        return input_shape[0]\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 2\n","        assert len(input_shape[0]) == 3\n","        assert len(input_shape[1]) == 2\n","        n_steps = input_shape[0][1]\n","        n_classes = input_shape[0][2]\n","        assert n_steps is None or n_steps >= 2\n","\n","        self.transition_params = self.add_weight(shape=(n_classes, n_classes),\n","                                                 initializer='uniform',\n","                                                 name='transition')\n","        self.input_spec = [InputSpec(dtype=K.floatx(), shape=(None, n_steps, n_classes)),\n","                           InputSpec(dtype='int32', shape=(None, 1))]\n","        self.built = True\n","\n","    def viterbi_decode(self, potentials, sequence_length):\n","        decode_tags, best_score = crf_decode(potentials, self.transition_params, sequence_length)\n","        return decode_tags\n","\n","    def call(self, inputs, mask=None, **kwargs):\n","        inputs, sequence_lengths = inputs\n","        self.sequence_lengths = K.flatten(sequence_lengths)\n","        y_pred = self.viterbi_decode(inputs, self.sequence_lengths)\n","        nb_classes = self.input_spec[0].shape[2]\n","        y_pred_one_hot = K.one_hot(y_pred, nb_classes)\n","\n","        return K.in_train_phase(inputs, y_pred_one_hot)\n","\n","    def loss(self, y_true, y_pred):\n","        y_true = K.cast(K.argmax(y_true, axis=-1), dtype='int32')\n","        log_likelihood, self.transition_params = tfa.text.crf.crf_log_likelihood(\n","            y_pred, y_true, self.sequence_lengths, self.transition_params)\n","        loss = tf.reduce_mean(-log_likelihood)\n","\n","        return loss\n","\n","    def get_config(self):\n","        config = {\n","            'transition_params': K.eval(self.transition_params),\n","        }\n","        base_config = super(CRFLayer, self).get_config()\n","\n","        return dict(list(base_config.items()) + list(config.items()))\n","\n","\n","def create_custom_objects():\n","    instanceHolder = {'instance': None}\n","\n","    class ClassWrapper(CRFLayer):\n","        def __init__(self, *args, **kwargs):\n","            instanceHolder['instance'] = self\n","            super(ClassWrapper, self).__init__(*args, **kwargs)\n","\n","    def loss(*args):\n","        method = getattr(instanceHolder['instance'], 'loss')\n","        return method(*args)\n","\n","    return {'CRFLayer': ClassWrapper, 'loss': loss}"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nqeMTLB0bRNv"},"source":["# NER model"]},{"cell_type":"code","metadata":{"id":"bHiNwUDqyugU","executionInfo":{"status":"ok","timestamp":1611441135919,"user_tz":-210,"elapsed":714,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}}},"source":["tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","# base_model = TFBertModel.from_pretrained('bert-base-uncased')"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"FeR_L9Xfq1lP","executionInfo":{"status":"ok","timestamp":1611441137117,"user_tz":-210,"elapsed":780,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}}},"source":["def createToxicModelWithGivenBaseModel(max_input_length,base_model):\n","    input_ids_layer = layers.Input(shape=(max_input_length,),name=\"encoder_input_ids\",dtype=tf.int32)\n","    input_attention_mask_layer = layers.Input(shape=(max_input_length,),name=\"encoder_attention_mask\",dtype=tf.int32)\n","    input_length = layers.Input(shape=(1,),name=\"length\",dtype=tf.int32)\n","    base_model.trainable = True\n","    base_model = base_model(input_ids_layer,attention_mask=input_attention_mask_layer,return_dict=True)\n","    output = layers.Dropout(0.1)(base_model.last_hidden_state)\n","    output = layers.Dense(1024,activation=\"relu\")(output)\n","    output = layers.Dropout(0.1)(output)\n","    output = layers.Dense(1024,activation=\"relu\")(output)\n","    output = layers.Dense(3,activation=\"linear\")(output)\n","    crf = CRFLayer()\n","    output = crf(inputs=[output,input_length])\n","    model = models.Model(inputs=[input_ids_layer,input_attention_mask_layer,input_length],outputs=output)\n","    model.compile(optimizer=optimizers.Adam(learning_rate=3e-5),loss=crf.loss,metrics=['accuracy'])\n","    return model"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"-3v8iA14by0o","executionInfo":{"status":"ok","timestamp":1611441138624,"user_tz":-210,"elapsed":733,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}}},"source":["max_length = 400"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"6TrD_b9_hFch","executionInfo":{"status":"ok","timestamp":1611441147221,"user_tz":-210,"elapsed":3919,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}}},"source":["texts = toxic_span_dataset['text'].to_numpy()\n","targets = createNEROutputs(texts,toxic_span_dataset['spans'],max_length,tokenizer)\n","all_spans = toxic_span_dataset['spans'].to_numpy()\n","result_test = []\n","result_train = []\n","kf = KFold(n_splits=5)\n","train_test_indices = []\n","for train_index,test_index in kf.split(texts):\n","    train_test_indices.append((train_index,test_index))"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":840,"referenced_widgets":["9441d6b4425343fa835047b25e2f6d93","cf432f2397eb468b990c7bdf23506f24","f3dbb486c88f40ba8486b6d12ed5f55f","58df53fe8a224e5b96d23876d22d9ca1","269f9dce06f14c34a491e35b95a72248","544ad5a619fc46feb1f0f5557329e0a5","78172c8fcc9142b4bc442af68f33e196","1018b934d96c429487e1ed60228bac70","2962b265d8b24fc7ad106163833a58c4","f475adb86ff54646ae4aa7729e0aefc4","cf0b2490176a4c60bb66fbb4c0d32e26","07e9040425834cce9420f00035b09b29","0d07a380c35c47dc9fa99eafca7ad606","5e09ce6254914c56a40db89feb6cd81a","bd6458143a374d60981bba258c3f7b3c","f8a0af4fd23546168fbc92771ec10c2d"]},"id":"8iZstls4d923","executionInfo":{"status":"ok","timestamp":1611430114492,"user_tz":-210,"elapsed":2251537,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}},"outputId":"b067cd77-0f71-45ff-c419-7aadc460e104"},"source":["train_index,test_index = train_test_indices.pop()\n","x_train , x_test = list(texts[train_index]) , list(texts[test_index])\n","y_train , y_test = targets[train_index] , targets[test_index]\n","model = None\n","base_model = None\n","gc.collect()\n","tf.keras.backend.clear_session()\n","base_model = TFRobertaModel.from_pretrained('roberta-base')\n","model = createToxicModelWithGivenBaseModel(max_length,base_model)\n","train_data = createInputForNER(x_train,max_length,tokenizer)\n","test_data = createInputForNER(x_test,max_length,tokenizer)\n","spans_test = all_spans[test_index]\n","spans_train = all_spans[train_index]\n","model.fit(train_data,y_train,batch_size=16,epochs=2,callbacks=[callbacks.ModelCheckpoint(\"/content/drive/MyDrive/toxic span/final saved models/NER/roberta/crf/ner\",save_weights_only=True)])\n","preds = model.predict(test_data)\n","indices = createIndicesForNERModel(preds,x_test,tokenizer)\n","f1_toxic = avg_f1(indices,spans_test)\n","print(\"test F1 = %f\"%(f1_toxic))\n","result_test.append(f1_toxic)\n","preds = model.predict(train_data)\n","indices = createIndicesForNERModel(preds,x_train,tokenizer)\n","f1_toxic = avg_f1(indices,spans_train)\n","print(\"train F1 = %f\"%(f1_toxic))\n","result_train.append(f1_toxic)"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9441d6b4425343fa835047b25e2f6d93","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2962b265d8b24fc7ad106163833a58c4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=657434796.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n","- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f47650b8590>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: <cyfunction Socket.send at 0x7f4782a59d90> is not a module, class, method, function, traceback, frame, or code object\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f47650b8590>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: <cyfunction Socket.send at 0x7f4782a59d90> is not a module, class, method, function, traceback, frame, or code object\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f47803eb9d8> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function wrap at 0x7f47803eb9d8> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-13-055edcdc8af2>:68: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/2\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n","432/432 [==============================] - 873s 2s/step - loss: 13.5227 - accuracy: 0.1107\n","Epoch 2/2\n","432/432 [==============================] - 873s 2s/step - loss: 9.3907 - accuracy: 0.1105\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["test F1 = 0.669012\n","train F1 = 0.697562\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VDKqMaWkjoEP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611432604070,"user_tz":-210,"elapsed":2271156,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}},"outputId":"b91b4d5c-4690-4055-e869-5b3631b4f0b5"},"source":["train_index,test_index = train_test_indices.pop()\n","x_train , x_test = list(texts[train_index]) , list(texts[test_index])\n","y_train , y_test = targets[train_index] , targets[test_index]\n","model = None\n","base_model = None\n","gc.collect()\n","tf.keras.backend.clear_session()\n","base_model = TFRobertaModel.from_pretrained('roberta-base')\n","model = createToxicModelWithGivenBaseModel(max_length,base_model)\n","train_data = createInputForNER(x_train,max_length,tokenizer)\n","test_data = createInputForNER(x_test,max_length,tokenizer)\n","spans_test = all_spans[test_index]\n","spans_train = all_spans[train_index]\n","model.fit(train_data,y_train,batch_size=16,epochs=2,callbacks=[callbacks.ModelCheckpoint(\"/content/drive/MyDrive/toxic span/final saved models/NER/roberta/crf/ner\",save_weights_only=True)])\n","preds = model.predict(test_data)\n","indices = createIndicesForNERModel(preds,x_test,tokenizer)\n","f1_toxic = avg_f1(indices,spans_test)\n","print(\"test F1 = %f\"%(f1_toxic))\n","result_test.append(f1_toxic)\n","preds = model.predict(train_data)\n","indices = createIndicesForNERModel(preds,x_train,tokenizer)\n","f1_toxic = avg_f1(indices,spans_train)\n","print(\"train F1 = %f\"%(f1_toxic))\n","result_train.append(f1_toxic)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n","- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f70e2cf8590>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: <cyfunction Socket.send at 0x7f71006a2d90> is not a module, class, method, function, traceback, frame, or code object\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f70e2cf8590>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: <cyfunction Socket.send at 0x7f71006a2d90> is not a module, class, method, function, traceback, frame, or code object\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f70fe0319d8> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function wrap at 0x7f70fe0319d8> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-10-055edcdc8af2>:68: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/2\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n","432/432 [==============================] - 881s 2s/step - loss: 13.4168 - accuracy: 0.1310\n","Epoch 2/2\n","432/432 [==============================] - 881s 2s/step - loss: 9.7399 - accuracy: 0.1124\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["test F1 = 0.641732\n","train F1 = 0.686007\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bgmycsljjo5B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611434879081,"user_tz":-210,"elapsed":4537285,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}},"outputId":"f8965e89-7cdb-4def-b836-d2e7fa74f520"},"source":["train_index,test_index = train_test_indices.pop()\n","x_train , x_test = list(texts[train_index]) , list(texts[test_index])\n","y_train , y_test = targets[train_index] , targets[test_index]\n","model = None\n","base_model = None\n","gc.collect()\n","tf.keras.backend.clear_session()\n","base_model = TFRobertaModel.from_pretrained('roberta-base')\n","model = createToxicModelWithGivenBaseModel(max_length,base_model)\n","train_data = createInputForNER(x_train,max_length,tokenizer)\n","test_data = createInputForNER(x_test,max_length,tokenizer)\n","spans_test = all_spans[test_index]\n","spans_train = all_spans[train_index]\n","model.fit(train_data,y_train,batch_size=16,epochs=2,callbacks=[callbacks.ModelCheckpoint(\"/content/drive/MyDrive/toxic span/final saved models/NER/roberta/crf/ner\",save_weights_only=True)])\n","preds = model.predict(test_data)\n","indices = createIndicesForNERModel(preds,x_test,tokenizer)\n","f1_toxic = avg_f1(indices,spans_test)\n","print(\"test F1 = %f\"%(f1_toxic))\n","result_test.append(f1_toxic)\n","preds = model.predict(train_data)\n","indices = createIndicesForNERModel(preds,x_train,tokenizer)\n","f1_toxic = avg_f1(indices,spans_train)\n","print(\"train F1 = %f\"%(f1_toxic))\n","result_train.append(f1_toxic)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n","- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/2\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n","432/432 [==============================] - 898s 2s/step - loss: 13.7566 - accuracy: 0.1239\n","Epoch 2/2\n","432/432 [==============================] - 891s 2s/step - loss: 10.4283 - accuracy: 0.1134\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["test F1 = 0.650876\n","train F1 = 0.680228\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m_wEmISWjpui","executionInfo":{"status":"ok","timestamp":1611437178052,"user_tz":-210,"elapsed":6831901,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}},"outputId":"f6712921-2844-4623-e3b4-dc2791d43d92"},"source":["train_index,test_index = train_test_indices.pop()\n","x_train , x_test = list(texts[train_index]) , list(texts[test_index])\n","y_train , y_test = targets[train_index] , targets[test_index]\n","model = None\n","base_model = None\n","gc.collect()\n","tf.keras.backend.clear_session()\n","base_model = TFRobertaModel.from_pretrained('roberta-base')\n","model = createToxicModelWithGivenBaseModel(max_length,base_model)\n","train_data = createInputForNER(x_train,max_length,tokenizer)\n","test_data = createInputForNER(x_test,max_length,tokenizer)\n","spans_test = all_spans[test_index]\n","spans_train = all_spans[train_index]\n","model.fit(train_data,y_train,batch_size=16,epochs=2,callbacks=[callbacks.ModelCheckpoint(\"/content/drive/MyDrive/toxic span/final saved models/NER/roberta/crf/ner\",save_weights_only=True)])\n","preds = model.predict(test_data)\n","indices = createIndicesForNERModel(preds,x_test,tokenizer)\n","f1_toxic = avg_f1(indices,spans_test)\n","print(\"test F1 = %f\"%(f1_toxic))\n","result_test.append(f1_toxic)\n","preds = model.predict(train_data)\n","indices = createIndicesForNERModel(preds,x_train,tokenizer)\n","f1_toxic = avg_f1(indices,spans_train)\n","print(\"train F1 = %f\"%(f1_toxic))\n","result_train.append(f1_toxic)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n","- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/2\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n","432/432 [==============================] - 909s 2s/step - loss: 13.5002 - accuracy: 0.1125\n","Epoch 2/2\n","432/432 [==============================] - 901s 2s/step - loss: 9.8289 - accuracy: 0.1134\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["test F1 = 0.654527\n","train F1 = 0.679480\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ECUkmb47jr70","executionInfo":{"status":"ok","timestamp":1611439455167,"user_tz":-210,"elapsed":9107371,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}},"outputId":"21cb0aa4-eea4-4c04-b428-b8e32cdc3e52"},"source":["train_index,test_index = train_test_indices.pop()\n","x_train , x_test = list(texts[train_index]) , list(texts[test_index])\n","y_train , y_test = targets[train_index] , targets[test_index]\n","model = None\n","base_model = None\n","gc.collect()\n","tf.keras.backend.clear_session()\n","base_model = TFRobertaModel.from_pretrained('roberta-base')\n","model = createToxicModelWithGivenBaseModel(max_length,base_model)\n","train_data = createInputForNER(x_train,max_length,tokenizer)\n","test_data = createInputForNER(x_test,max_length,tokenizer)\n","spans_test = all_spans[test_index]\n","spans_train = all_spans[train_index]\n","model.fit(train_data,y_train,batch_size=16,epochs=2,callbacks=[callbacks.ModelCheckpoint(\"/content/drive/MyDrive/toxic span/final saved models/NER/roberta/crf/ner\",save_weights_only=True)])\n","preds = model.predict(test_data)\n","indices = createIndicesForNERModel(preds,x_test,tokenizer)\n","f1_toxic = avg_f1(indices,spans_test)\n","print(\"test F1 = %f\"%(f1_toxic))\n","result_test.append(f1_toxic)\n","preds = model.predict(train_data)\n","indices = createIndicesForNERModel(preds,x_train,tokenizer)\n","f1_toxic = avg_f1(indices,spans_train)\n","print(\"train F1 = %f\"%(f1_toxic))\n","result_train.append(f1_toxic)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n","- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/2\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n","432/432 [==============================] - 901s 2s/step - loss: 13.9192 - accuracy: 0.1161\n","Epoch 2/2\n","432/432 [==============================] - 894s 2s/step - loss: 10.2825 - accuracy: 0.1123\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["test F1 = 0.646850\n","train F1 = 0.668697\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aTOstzX3hazN","executionInfo":{"status":"ok","timestamp":1611439520059,"user_tz":-210,"elapsed":706,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}},"outputId":"35d36b2c-fd2a-430e-940b-d223631dcbaf"},"source":["f1_toxic = sum(result_test)/5\n","print(\"final test F1 = %f\"%(f1_toxic))\n","f1_toxic = sum(result_train)/5\n","print(\"final train F1 = %f\"%(f1_toxic))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["final test F1 = 0.652599\n","final train F1 = 0.682395\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3SUX33GhK87j"},"source":["# train on random part of dataset to save a check point"]},{"cell_type":"code","metadata":{"id":"94UPmXESLKuN","executionInfo":{"status":"ok","timestamp":1611441157621,"user_tz":-210,"elapsed":3032,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}}},"source":["toxic_span_dataset = toxic_span_dataset.sample(frac=1)\n","texts = toxic_span_dataset['text'].to_numpy()\n","targets = createNEROutputs(texts,toxic_span_dataset['spans'],max_length,tokenizer)\n","all_spans = toxic_span_dataset['spans'].to_numpy()\n","result_test = []\n","result_train = []\n","kf = KFold(n_splits=5,shuffle=True)\n","train_test_indices = []\n","for train_index,test_index in kf.split(texts):\n","    train_test_indices.append((train_index,test_index))"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DvQAzBq2LHuf","executionInfo":{"status":"ok","timestamp":1611443452339,"user_tz":-210,"elapsed":2291984,"user":{"displayName":"Alireza Salemi","photoUrl":"","userId":"11780824467000739064"}},"outputId":"c712abfe-f82a-4a25-e070-d118e7905c82"},"source":["train_index,test_index = train_test_indices.pop()\n","x_train , x_test = list(texts[train_index]) , list(texts[test_index])\n","y_train , y_test = targets[train_index] , targets[test_index]\n","model = None\n","base_model = None\n","gc.collect()\n","tf.keras.backend.clear_session()\n","base_model = TFRobertaModel.from_pretrained('roberta-base')\n","model = createToxicModelWithGivenBaseModel(max_length,base_model)\n","train_data = createInputForNER(x_train,max_length,tokenizer)\n","test_data = createInputForNER(x_test,max_length,tokenizer)\n","spans_test = all_spans[test_index]\n","spans_train = all_spans[train_index]\n","model.fit(train_data,y_train,batch_size=16,epochs=2,callbacks=[callbacks.ModelCheckpoint(\"/content/drive/MyDrive/toxic span/final saved models/NER/roberta/crf/ner\",save_weights_only=True)])\n","preds = model.predict(test_data)\n","indices = createIndicesForNERModel(preds,x_test,tokenizer)\n","f1_toxic = avg_f1(indices,spans_test)\n","print(\"test F1 = %f\"%(f1_toxic))\n","result_test.append(f1_toxic)\n","preds = model.predict(train_data)\n","indices = createIndicesForNERModel(preds,x_train,tokenizer)\n","f1_toxic = avg_f1(indices,spans_train)\n","print(\"train F1 = %f\"%(f1_toxic))\n","result_train.append(f1_toxic)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n","- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f36e5dd3590>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: <cyfunction Socket.send at 0x7f370377dd90> is not a module, class, method, function, traceback, frame, or code object\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f36e5dd3590>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: <cyfunction Socket.send at 0x7f370377dd90> is not a module, class, method, function, traceback, frame, or code object\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f370110c9d8> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function wrap at 0x7f370110c9d8> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-10-055edcdc8af2>:68: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/2\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n","432/432 [==============================] - 896s 2s/step - loss: 12.5695 - accuracy: 0.1113\n","Epoch 2/2\n","432/432 [==============================] - 891s 2s/step - loss: 9.2199 - accuracy: 0.1091\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["test F1 = 0.629671\n","train F1 = 0.667740\n"],"name":"stdout"}]}]}